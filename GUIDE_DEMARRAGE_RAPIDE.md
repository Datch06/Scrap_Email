# ğŸš€ Guide de DÃ©marrage Rapide - Scraping Asynchrone

## Vue d'ensemble

Ce guide vous permet de dÃ©marrer rapidement avec le nouveau systÃ¨me de scraping asynchrone, **4-5x plus rapide** que l'ancien systÃ¨me.

---

## âš¡ Commandes Essentielles

### 1. VÃ©rifier les Statistiques

```bash
cd /var/www/Scrap_Email
python3 check_stats.py
```

**RÃ©sultat:**
```
============================================================
ğŸ“Š STATISTIQUES BASE DE DONNÃ‰ES
============================================================
Total sites: 79,430
Sites avec emails: 24,878 (31.3%)
Sites sans emails: 54,552 (68.7%)
Emails validÃ©s: 22,907
============================================================
```

---

### 2. Tester sur Quelques Sites (Test Rapide)

```bash
python3 test_async_scraper.py
```

**UtilitÃ©:** Tester le finder sur 5 sites de la base

---

### 3. Re-scraper 100 Sites (Validation)

```bash
python3 rescrape_no_emails_async.py --limit 100
```

**Temps estimÃ©:** 1-2 minutes
**UtilitÃ©:** Valider que le systÃ¨me fonctionne correctement

---

### 4. Re-scraper 1000 Sites (Test Ã‰tendu)

```bash
python3 rescrape_no_emails_async.py --limit 1000 --concurrent 30
```

**Temps estimÃ©:** 8-12 minutes
**UtilitÃ©:** Test de production avant dÃ©ploiement complet

---

### 5. Re-scraper TOUS les Sites Sans Emails

```bash
python3 rescrape_no_emails_async.py
```

**Sites Ã  traiter:** 54,552
**Temps estimÃ©:** 6-8 heures
**Emails attendus:** 5,000-8,000 valides

---

### 6. Scraper LinkAvista (Nouveau)

```bash
python3 scrape_async_linkavista.py
```

**RÃ©sultat attendu:** 15,000+ nouveaux domaines
**Temps:** 6-10 minutes
**Emails:** 1,500-2,500 emails

---

### 7. Nettoyer les Faux Positifs

```bash
python3 clean_all_invalid.py
```

**UtilitÃ©:** Supprimer tous les emails invalides de la base

---

## ğŸ›ï¸ Options AvancÃ©es

### Re-scraping avec Options

```bash
# Limiter Ã  N sites
python3 rescrape_no_emails_async.py --limit 500

# Augmenter la concurrence (serveur puissant)
python3 rescrape_no_emails_async.py --limit 1000 --concurrent 40

# Modifier la taille des lots
python3 rescrape_no_emails_async.py --limit 1000 --batch-size 100
```

### Options Disponibles

| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `--limit N` | Nombre max de sites | Aucun (tous) |
| `--concurrent N` | RequÃªtes simultanÃ©es | 30 |
| `--batch-size N` | Taille des lots | 50 |

---

## ğŸ“Š Workflow RecommandÃ©

### Phase 1: Validation (FAIT âœ…)

```bash
# 1. Test rapide
python3 test_async_scraper.py

# 2. Test 100 sites
python3 rescrape_no_emails_async.py --limit 100

# 3. VÃ©rifier les stats
python3 check_stats.py
```

### Phase 2: Test Ã‰tendu (EN COURS â³)

```bash
# Test 1000 sites
python3 rescrape_no_emails_async.py --limit 1000 --concurrent 30

# VÃ©rifier les rÃ©sultats
python3 check_stats.py

# Valider manuellement quelques emails
# (VÃ©rifier dans la base que les emails sont rÃ©els)
```

### Phase 3: DÃ©ploiement Complet (Ã€ FAIRE)

```bash
# Re-scraper TOUS les sites sans emails
python3 rescrape_no_emails_async.py

# Temps: 6-8 heures
# Recommandation: Lancer la nuit ou le weekend
```

### Phase 4: Scraping Nouveau (Ã€ FAIRE)

```bash
# Scraper LinkAvista pour nouveaux domaines
python3 scrape_async_linkavista.py

# Temps: 6-10 minutes
# RÃ©sultat: 15,000+ nouveaux domaines
```

---

## ğŸ“ Conseils d'Utilisation

### Performance

**Si trop lent:**
- Augmenter `--concurrent` Ã  40-50
- VÃ©rifier la bande passante rÃ©seau

**Si trop d'erreurs:**
- Diminuer `--concurrent` Ã  20-25
- Augmenter le timeout dans le code

### Monitoring

**Pendant le scraping:**
```bash
# Voir la progression en temps rÃ©el
tail -f /var/log/rescrape.log

# Ou surveiller les stats
watch -n 60 'python3 check_stats.py'
```

### ArrÃªt d'Urgence

**Si besoin d'arrÃªter:**
```bash
# Ctrl+C dans le terminal
# Ou
pkill -f rescrape_no_emails_async
```

Les changements en cours sont sauvegardÃ©s par lots, donc peu de perte.

---

## ğŸ› DÃ©pannage

### "Too many open files"

```bash
ulimit -n 4096
# Puis relancer le script
```

### "Database is locked"

SQLite peut Ãªtre bloquÃ© avec trop de writes simultanÃ©s.

**Solution:**
```bash
# Diminuer batch_size
python3 rescrape_no_emails_async.py --limit 1000 --batch-size 25
```

### "Connection timeout"

Sites trop lents ou indisponibles.

**Solution:** Le script gÃ¨re automatiquement les timeouts et continue.

---

## ğŸ“ˆ RÃ©sultats Attendus

### Test 1000 Sites

**Avant (ancien systÃ¨me):**
- Temps: ~30 minutes
- Emails: 100-150 (10-15%)
- Faux positifs: 30-50%

**AprÃ¨s (nouveau systÃ¨me):**
- Temps: ~8-12 minutes (3-4x plus rapide)
- Emails: 100-150 (10-15%)
- Faux positifs: 0% (validation stricte)

### DÃ©ploiement Complet (54,000 sites)

**Estimation rÃ©aliste:**
- Temps: 6-8 heures
- Emails trouvÃ©s: 5,000-8,000 (10-15%)
- QualitÃ©: 100% d'emails valides
- Taux de dÃ©couverte: Meilleur que l'ancien systÃ¨me grÃ¢ce Ã  8-10 pages vÃ©rifiÃ©es

---

## âœ… Checklist de DÃ©marrage

**Avant de lancer le dÃ©ploiement complet:**

- [ ] Test 100 sites effectuÃ© âœ…
- [ ] Test 1000 sites effectuÃ© â³
- [ ] Validation manuelle de 50 emails â³
- [ ] Aucun faux positif dÃ©tectÃ© âœ…
- [ ] Stats vÃ©rifiÃ©es âœ…
- [ ] Backup de la base effectuÃ© â³

**Backup de la base:**
```bash
cd /var/www/Scrap_Email
cp scrap_email.db scrap_email_backup_$(date +%Y%m%d).db
```

---

## ğŸ¯ Objectifs

**Court terme (cette semaine):**
- âœ… SystÃ¨me asynchrone dÃ©ployÃ©
- âœ… Validation stricte implÃ©mentÃ©e
- â³ Test 1000 sites validÃ©
- â³ DÃ©ploiement complet lancÃ©

**Moyen terme (ce mois):**
- â³ 30,000+ emails valides en base
- â³ Scraping LinkAvista rÃ©gulier (1x/semaine)
- â³ Re-scraping pÃ©riodique automatisÃ©

**Long terme (3 mois):**
- â³ 50,000+ emails valides
- â³ Nouvelles sources ajoutÃ©es (Majestic, Ahrefs)
- â³ Validation en temps rÃ©el avec API

---

## ğŸ“ Support

**Documentation:**
- [SCRAPING_ASYNC.md](SCRAPING_ASYNC.md) - Guide complet
- [CHANGELOG_ASYNC.md](CHANGELOG_ASYNC.md) - Historique
- [RAPPORT_FINAL.md](RAPPORT_FINAL.md) - Rapport dÃ©taillÃ©

**Contact:**
- Email: david@somucom.com
- GitHub: https://github.com/Datch06/Scrap_Email

---

**PrÃªt Ã  dÃ©marrer ? Lancez la commande de test !** ğŸš€

```bash
python3 rescrape_no_emails_async.py --limit 1000 --concurrent 30
```
